{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question-Question LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-eTMk_CbtN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "39e4f69e-162a-4cd8-bd3f-a82766a44cd0"
      },
      "source": [
        "from time import time\n",
        "from __future__ import division, print_function\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, model_from_json, Sequential\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda, Softmax, Dense, Concatenate, Dropout, Add, add, concatenate, GRU\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adadelta, Adam\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7ISx3h9yOZh",
        "colab_type": "code",
        "outputId": "52d34494-6222-453d-eca7-c03dc6784fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8MrLIMqijt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_CSV = '/content/drive/My Drive/Sem 3-2/NLA/Project/train.csv'\n",
        "TEST_CSV = '/content/drive/My Drive/Sem 3-2/NLA/Project/test.csv'\n",
        "MODEL_SAVING_DIR = '/content/drive/My Drive/Sem 3-2/NLA/Project/Models/'\n",
        "\n",
        "# Make changes here for embedding and model name\n",
        "MODEL_NAME = 'lstm_glove_softmax'\n",
        "EMBEDDING_TYPE = 'glove' # w2v, glove2\n",
        "\n",
        "if EMBEDDING_TYPE == 'w2v':\n",
        "  EMBEDDING_FILE = '/content/drive/My Drive/Sem 3-2/NLA/Project/GoogleNews-vectors-negative300.bin.gz'\n",
        "elif EMBEDDING_TYPE == 'glove':\n",
        "  EMBEDDING_FILE = '/content/drive/My Drive/Sem 3-2/NLA/Project/glove/glove.6B.100d.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx0FbK8eyT74",
        "colab_type": "code",
        "outputId": "d274aa3e-a5a3-43aa-b664-00e4f22b0a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nueg0Fb0uiCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load training and test set\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words '''\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Prepare embedding\n",
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "\n",
        "if EMBEDDING_TYPE == 'w2v':\n",
        "  word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
        "\n",
        "elif EMBEDDING_TYPE == 'glove':\n",
        "  embeddings_index = dict()\n",
        "  glove_vocab = []\n",
        "  f = open(EMBEDDING_FILE)  # glove.6B.100d.txt\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    glove_vocab.append(word)\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "\n",
        "questions_cols = ['question1', 'question2']\n",
        "\n",
        "# Iterate over the questions only of both training and test datasets\n",
        "for index, row in train_df.iterrows():\n",
        "\n",
        "    for question in questions_cols:\n",
        "\n",
        "        q2n = []  # q2n -> question numbers representation\n",
        "        for word in text_to_word_list(row[question]):\n",
        "\n",
        "            # Stop word removal\n",
        "            if EMBEDDING_TYPE == 'w2v':\n",
        "              if word in stops and word not in word2vec.vocab:\n",
        "                  continue\n",
        "                  \n",
        "            elif EMBEDDING_TYPE == 'glove':\n",
        "              if word in stops and word not in glove_vocab:\n",
        "                continue\n",
        "\n",
        "            if word not in vocabulary:\n",
        "                vocabulary[word] = len(inverse_vocabulary)\n",
        "                q2n.append(len(inverse_vocabulary))\n",
        "                inverse_vocabulary.append(word)\n",
        "            else:\n",
        "                q2n.append(vocabulary[word])\n",
        "\n",
        "        # Replace questions as word to question as number representation\n",
        "        train_df.at[index, question] = q2n\n",
        "\n",
        "if EMBEDDING_TYPE == 'w2v':            \n",
        "  embedding_dim = 300\n",
        "  embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "  embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "  # Build the embedding matrix\n",
        "  for word, index in vocabulary.items():\n",
        "      if word in word2vec.vocab:\n",
        "          embeddings[index] = word2vec.word_vec(word)\n",
        "  del word2vec\n",
        "\n",
        "elif EMBEDDING_TYPE == 'glove':\n",
        "  embedding_dim = 100\n",
        "  vocabulary_size = len(vocabulary) + 1\n",
        "  embeddings = np.zeros((vocabulary_size, 100))\n",
        "  for word, index in vocabulary.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embeddings[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ZIE6zEl1Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = max(train_df.question1.map(lambda x: len(x)).max(),\n",
        "                     train_df.question2.map(lambda x: len(x)).max())\n",
        "\n",
        "# Split to train validation test\n",
        "test_size = 40000\n",
        "validation_size = 40000\n",
        "training_size = len(train_df) - validation_size - test_size\n",
        "\n",
        "X = train_df[questions_cols]\n",
        "Y = train_df['is_duplicate']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=validation_size)\n",
        "\n",
        "# Split to dicts\n",
        "X_train = {'left': X_train.question1, 'right': X_train.question2}\n",
        "X_validation = {'left': X_validation.question1, 'right': X_validation.question2}\n",
        "X_test = {'left': X_test.question1, 'right': X_test.question2}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values\n",
        "Y_test = Y_test.values\n",
        "\n",
        "# Zero padding\n",
        "for dataset, side in itertools.product([X_train, X_validation, X_test], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4lwWwU305ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    prec = precision(y_true, y_pred)\n",
        "    rec = recall(y_true, y_pred)\n",
        "    return 2*((prec*rec)/(prec + rec + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyKELgOE4olR",
        "colab_type": "code",
        "outputId": "5a4c1fa4-752e-4569-cee6-609070422f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        }
      },
      "source": [
        "# Model variables\n",
        "n_hidden = 64\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 2048\n",
        "n_epoch = 20\n",
        "\n",
        "def get_model(input_shape):\n",
        "  left_input = Input(shape=(input_shape,), dtype='int32')\n",
        "  right_input = Input(shape=(input_shape,), dtype='int32')\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=input_shape, trainable=False))\n",
        "  \n",
        "  model.add(LSTM(n_hidden))\n",
        "\n",
        "  left_output = model(left_input)\n",
        "  right_output = model(right_input)\n",
        "\n",
        "  addition_layer = Lambda(lambda tensors:(tensors[0]+tensors[1]))([left_output, right_output])\n",
        "  prediction = Dense(1, activation='sigmoid')(addition_layer)\n",
        "\n",
        "  siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
        "  return siamese_net\n",
        "\n",
        "lstm = get_model(max_seq_length)\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "lstm.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', recall, precision, f1])\n",
        "\n",
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "lstm_trained = lstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
        "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 324290 samples, validate on 40000 samples\n",
            "Epoch 1/20\n",
            "324290/324290 [==============================] - 120s 370us/step - loss: 0.6049 - accuracy: 0.6760 - recall: 0.3459 - precision: 0.6141 - f1: 0.4171 - val_loss: 0.5688 - val_accuracy: 0.7077 - val_recall: 0.4035 - val_precision: 0.6727 - val_f1: 0.5043\n",
            "Epoch 2/20\n",
            "324290/324290 [==============================] - 113s 350us/step - loss: 0.5571 - accuracy: 0.7161 - recall: 0.4772 - precision: 0.6668 - f1: 0.5511 - val_loss: 0.5511 - val_accuracy: 0.7218 - val_recall: 0.3891 - val_precision: 0.7297 - val_f1: 0.5075\n",
            "Epoch 3/20\n",
            "324290/324290 [==============================] - 111s 343us/step - loss: 0.5395 - accuracy: 0.7297 - recall: 0.5025 - precision: 0.6851 - f1: 0.5776 - val_loss: 0.5353 - val_accuracy: 0.7361 - val_recall: 0.5137 - val_precision: 0.6910 - val_f1: 0.5892\n",
            "Epoch 4/20\n",
            "324290/324290 [==============================] - 109s 338us/step - loss: 0.5289 - accuracy: 0.7381 - recall: 0.5232 - precision: 0.6966 - f1: 0.5948 - val_loss: 0.5261 - val_accuracy: 0.7408 - val_recall: 0.5147 - val_precision: 0.7022 - val_f1: 0.5937\n",
            "Epoch 5/20\n",
            "324290/324290 [==============================] - 109s 337us/step - loss: 0.5204 - accuracy: 0.7443 - recall: 0.5368 - precision: 0.7040 - f1: 0.6070 - val_loss: 0.5291 - val_accuracy: 0.7377 - val_recall: 0.6380 - val_precision: 0.6460 - val_f1: 0.6418\n",
            "Epoch 6/20\n",
            "324290/324290 [==============================] - 109s 336us/step - loss: 0.5150 - accuracy: 0.7484 - recall: 0.5478 - precision: 0.7100 - f1: 0.6150 - val_loss: 0.5160 - val_accuracy: 0.7491 - val_recall: 0.5092 - val_precision: 0.7276 - val_f1: 0.5990\n",
            "Epoch 7/20\n",
            "324290/324290 [==============================] - 108s 333us/step - loss: 0.5090 - accuracy: 0.7525 - recall: 0.5570 - precision: 0.7144 - f1: 0.6234 - val_loss: 0.5121 - val_accuracy: 0.7529 - val_recall: 0.5451 - val_precision: 0.7165 - val_f1: 0.6190\n",
            "Epoch 8/20\n",
            "324290/324290 [==============================] - 109s 338us/step - loss: 0.5041 - accuracy: 0.7555 - recall: 0.5637 - precision: 0.7180 - f1: 0.6288 - val_loss: 0.5110 - val_accuracy: 0.7509 - val_recall: 0.6050 - val_precision: 0.6827 - val_f1: 0.6414\n",
            "Epoch 9/20\n",
            "324290/324290 [==============================] - 109s 335us/step - loss: 0.4991 - accuracy: 0.7594 - recall: 0.5712 - precision: 0.7220 - f1: 0.6362 - val_loss: 0.5107 - val_accuracy: 0.7503 - val_recall: 0.6252 - val_precision: 0.6737 - val_f1: 0.6485\n",
            "Epoch 10/20\n",
            "324290/324290 [==============================] - 108s 334us/step - loss: 0.4960 - accuracy: 0.7605 - recall: 0.5759 - precision: 0.7238 - f1: 0.6385 - val_loss: 0.5046 - val_accuracy: 0.7571 - val_recall: 0.5256 - val_precision: 0.7395 - val_f1: 0.6143\n",
            "Epoch 11/20\n",
            "324290/324290 [==============================] - 109s 336us/step - loss: 0.4910 - accuracy: 0.7643 - recall: 0.5826 - precision: 0.7271 - f1: 0.6454 - val_loss: 0.5049 - val_accuracy: 0.7543 - val_recall: 0.6317 - val_precision: 0.6790 - val_f1: 0.6544\n",
            "Epoch 12/20\n",
            "324290/324290 [==============================] - 109s 336us/step - loss: 0.4880 - accuracy: 0.7662 - recall: 0.5872 - precision: 0.7308 - f1: 0.6489 - val_loss: 0.5049 - val_accuracy: 0.7535 - val_recall: 0.6502 - val_precision: 0.6706 - val_f1: 0.6601\n",
            "Epoch 13/20\n",
            "324290/324290 [==============================] - 108s 334us/step - loss: 0.4856 - accuracy: 0.7676 - recall: 0.5911 - precision: 0.7327 - f1: 0.6515 - val_loss: 0.4997 - val_accuracy: 0.7613 - val_recall: 0.6029 - val_precision: 0.7063 - val_f1: 0.6504\n",
            "Epoch 14/20\n",
            "324290/324290 [==============================] - 107s 331us/step - loss: 0.4822 - accuracy: 0.7699 - recall: 0.5963 - precision: 0.7352 - f1: 0.6558 - val_loss: 0.4971 - val_accuracy: 0.7615 - val_recall: 0.5760 - val_precision: 0.7205 - val_f1: 0.6401\n",
            "Epoch 15/20\n",
            "324290/324290 [==============================] - 109s 335us/step - loss: 0.4788 - accuracy: 0.7723 - recall: 0.6013 - precision: 0.7373 - f1: 0.6601 - val_loss: 0.4958 - val_accuracy: 0.7621 - val_recall: 0.5740 - val_precision: 0.7231 - val_f1: 0.6398\n",
            "Epoch 16/20\n",
            "324290/324290 [==============================] - 108s 332us/step - loss: 0.4752 - accuracy: 0.7742 - recall: 0.6054 - precision: 0.7391 - f1: 0.6638 - val_loss: 0.4958 - val_accuracy: 0.7628 - val_recall: 0.6109 - val_precision: 0.7058 - val_f1: 0.6547\n",
            "Epoch 17/20\n",
            "324290/324290 [==============================] - 109s 336us/step - loss: 0.4720 - accuracy: 0.7759 - recall: 0.6101 - precision: 0.7404 - f1: 0.6675 - val_loss: 0.4947 - val_accuracy: 0.7659 - val_recall: 0.5586 - val_precision: 0.7425 - val_f1: 0.6373\n",
            "Epoch 18/20\n",
            "324290/324290 [==============================] - 109s 335us/step - loss: 0.4692 - accuracy: 0.7779 - recall: 0.6141 - precision: 0.7424 - f1: 0.6708 - val_loss: 0.4923 - val_accuracy: 0.7661 - val_recall: 0.5980 - val_precision: 0.7199 - val_f1: 0.6531\n",
            "Epoch 19/20\n",
            "324290/324290 [==============================] - 109s 336us/step - loss: 0.4672 - accuracy: 0.7793 - recall: 0.6184 - precision: 0.7446 - f1: 0.6735 - val_loss: 0.4910 - val_accuracy: 0.7656 - val_recall: 0.5837 - val_precision: 0.7260 - val_f1: 0.6470\n",
            "Epoch 20/20\n",
            "324290/324290 [==============================] - 108s 333us/step - loss: 0.4642 - accuracy: 0.7810 - recall: 0.6199 - precision: 0.7464 - f1: 0.6759 - val_loss: 0.4977 - val_accuracy: 0.7606 - val_recall: 0.6710 - val_precision: 0.6761 - val_f1: 0.6734\n",
            "Training time finished.\n",
            "20 epochs in 0:36:32.377019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46hMuYjL2rDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# serialize model to JSON\n",
        "model_json = lstm.to_json()\n",
        "with open(MODEL_SAVING_DIR + MODEL_NAME + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "lstm.save_weights(MODEL_SAVING_DIR + MODEL_NAME + \".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Ias4_YlwZy",
        "colab_type": "code",
        "outputId": "8062044b-090f-412a-eb69-2785bc6f79e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "loss, acc, rec, prec, f1 = lstm.evaluate([X_test['left'], X_test['right']], Y_test)\n",
        "print(\"Loss =\", loss, \"Accuracy =\", acc, \"Recall =\", rec, \"Precision =\", prec, \"F1 =\", f1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "pred = lstm.predict([X_test['left'], X_test['right']])\n",
        "cm = confusion_matrix(Y_test, pred.round())\n",
        "cm_img = sn.heatmap(cm, annot=True)\n",
        "\n",
        "figure = cm_img.get_figure()    \n",
        "figure.savefig(MODEL_SAVING_DIR + MODEL_NAME + '.png', dpi=400)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 129s 3ms/step\n",
            "Loss = 0.5000596483707428 Accuracy = 0.7559750080108643 Recall = 0.6636674404144287 Precision = 0.6700536012649536 F1 = 0.6570401191711426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShzPX6Nw3O8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load json and create model\n",
        "json_file = open(MODEL_SAVING_DIR + MODEL_NAME + \".json\", 'rb')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "lstm = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "lstm.load_weights(MODEL_SAVING_DIR + MODEL_NAME +\".h5\")\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "lstm.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', recall, precision, f1])\n",
        "\n",
        "loss, acc, rec, prec, f1 = lstm.evaluate([X_test['left'], X_test['right']], Y_test)\n",
        "print(\"Loss =\", loss, \"Accuracy =\", acc, \"Recall =\", rec, \"Precision =\", prec, \"F1 =\", f1)\n",
        "\n",
        "pred = lstm.predict([X_test['left'], X_test['right']])\n",
        "cm = confusion_matrix(Y_test, pred.round())\n",
        "sn.heatmap(cm, annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYNA0BEQl6Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot accuracy\n",
        "plt.plot(lstm_trained.history['accuracy'])\n",
        "plt.plot(lstm_trained.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.plot(lstm_trained.history['loss'])\n",
        "plt.plot(lstm_trained.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAr5PXuR9Mj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}